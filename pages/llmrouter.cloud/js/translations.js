export const translations = {
  pl: {
    // Header
    'header.menu.aria': 'OtwÃ³rz menu',
    'header.nav.description': 'FunkcjonalnoÅ›ci',
    'header.nav.security': 'BezpieczeÅ„stwo',
    'header.nav.performance': 'WydajnoÅ›Ä‡',
    'header.nav.useCases': 'Zastosowania',
    'header.nav.contact': 'Kontakt',
    'header.github.router.tooltip': 'gÅ‚Ã³wne repozytorium llm-router.cloud na GitHub',
    'header.github.page.tooltip': 'strona llmrouter na GitHub',

    // Hero
    'hero.title': 'Brama AI dla lokalnej i chmurowej infrastruktury LLM',
    'hero.subtitle.reliable': 'Niezawodny',
    'hero.subtitle.text': 'routing dla duÅ¼ych modeli jÄ™zykowych z wbudowanym',
    'hero.subtitle.security': 'zabezpieczeniem danych',
    'hero.description': 'Elastyczna brama open-source do zarzÄ…dzania lokalnymi wdroÅ¼eniami LLM (vLLM, Ollama, LM Studio) oraz dostawcami chmurowymi. Zapewnia inteligentnÄ… warstwÄ™ miÄ™dzy aplikacjami a modelami, oferujÄ…c zarzÄ…dzanie ruchem w czasie rzeczywistym, inteligentne rÃ³wnowaÅ¼enie obciÄ…Å¼enia miÄ™dzy lokalnymi i chmurowymi dostawcami oraz kompleksowe mechanizmy bezpieczeÅ„stwa, w tym maskowanie danych osobowych, anonimizacjÄ™ i filtrowanie treÅ›ci. Zbudowana na licencji <strong>Apache 2.0</strong>, zostaÅ‚a zaprojektowana dla zespoÅ‚Ã³w, ktÃ³re chcÄ… uruchamiaÄ‡ infrastrukturÄ™ AI lokalnie z opcjonalnym wsparciem dostawcÃ³w chmurowychâ€”dajÄ…c peÅ‚nÄ… kontrolÄ™ i elastycznoÅ›Ä‡.',
    'hero.cta.github': 'Zobacz na GitHub',
    'hero.cta.docs': 'Dokumentacja',

    // Features
    'features.title': 'Kompleksowe zarzÄ…dzanie infrastrukturÄ… LLM',
    'features.subtitle': '<strong>Kompletna</strong> platforma do zarzÄ…dzania <strong>lokalnymi wdroÅ¼eniami LLM (vLLM, Ollama, LM Studio) i opcjonalnie dostawcami chmurowymi</strong> w dowolnej skali. Zunifikowane zarzÄ…dzanie z produkcyjnym bezpieczeÅ„stwem i obserwowalnoÅ›ciÄ…. Architektura open-source umoÅ¼liwia dostosowywanie i rozwÃ³j wspierany przez spoÅ‚ecznoÅ›Ä‡. <strong>Uruchamiaj modele lokalnie</strong> z peÅ‚nÄ… kontrolÄ… nad infrastrukturÄ….',
    'features.anonymization.title': 'Wbudowana anonimizacja danych osobowych',
    'features.anonymization.desc': 'Wysokowydajny plugin <code>fast_masker</code> automatycznie wykrywa i maskuje wraÅ¼liwe dane, w tym numery identyfikacyjne, numery podatkowe, e-maile, numery kont, adresy IP i wiÄ™cej przed przesÅ‚aniem do dostawcÃ³w LLM. ZgodnoÅ›Ä‡ z RODO i SOC2 z zaÅ‚oÅ¼enia.',
    'features.loadbalancing.title': 'Elastyczne rÃ³wnowaÅ¼enie obciÄ…Å¼enia',
    'features.loadbalancing.desc': 'Cztery konfigurowalne strategie rÃ³wnowaÅ¼enia obciÄ…Å¼enia: <code>balanced</code>, <code>weighted</code>, <code>first_available</code>, <code>first_available_optim</code>. Optymalizacja wykorzystania zasobÃ³w i zapewnienie wysokiej dostÄ™pnoÅ›ci dla wdroÅ¼eÅ„ dowolnej wielkoÅ›ci.',
    'features.routing.title': 'Zunifikowany routing lokalny i chmurowy',
    'features.routing.desc': 'Pojedyncze REST API obsÅ‚ugujÄ…ce lokalnych dostawcÃ³w (Ollama, vLLM, LM Studio) oraz usÅ‚ugi chmurowe (OpenAI, Anthropic, itd.). Automatyczna konwersja protokoÅ‚Ã³w, pÅ‚ynne przeÅ‚Ä…czanie miÄ™dzy lokalnymi i chmurowymi dostawcami oraz inteligentna dystrybucja obciÄ…Å¼enia na wszystkich endpointach.',
    'features.monitoring.title': 'PeÅ‚na obserwowalnoÅ›Ä‡',
    'features.monitoring.desc': 'Natywna integracja z Prometheus dostarczajÄ…ca metryki w czasie rzeczywistym: wspÃ³Å‚czynniki Å¼Ä…daÅ„, percentyle opÃ³ÅºnieÅ„, wspÃ³Å‚czynniki bÅ‚Ä™dÃ³w na dostawcÄ™ oraz health checks. PeÅ‚na widocznoÅ›Ä‡ przez panele Grafana z automatycznym wykrywaniem usÅ‚ug i alertami.',
    'features.performance.title': 'Wysoka wydajnoÅ›Ä‡',
    'features.performance.desc': 'Strumieniowanie odpowiedzi, pooling poÅ‚Ä…czeÅ„, broker Redis do wdroÅ¼eÅ„ rozproszonych. Zoptymalizowane pod kÄ…tem minimalnego opÃ³Åºnienia i maksymalnej przepustowoÅ›ci w rÃ³Å¼nych scenariuszach wdroÅ¼eÅ„.',
    'features.config.title': 'Åatwe wdroÅ¼enie',
    'features.config.desc': 'Konfiguracja infrastruktury jako kodu przez JSON i zmienne Å›rodowiskowe. GotowoÅ›Ä‡ na Docker i Kubernetes z oficjalnymi obrazami. WdroÅ¼enie w minuty z elastycznymi opcjami konfiguracji dla dowolnego Å›rodowiska.',
    'features.endpoints.title': 'Rozszerzalne endpointy',
    'features.endpoints.desc': 'Gotowe do uÅ¼ycia endpointy dla pipeline\'Ã³w RAG, generowania pytaÅ„, tÅ‚umaczeÅ„ i innych typowych workflow AI. Åatwo rozszerzalne o niestandardowe przypadki uÅ¼ycia.',
    'features.web.title': 'Interfejsy zarzÄ…dzania',
    'features.web.desc': 'Configuration Manager do centralnej kontroli infrastruktury i interfejs Anonymizer do bezpiecznej, zgodnej komunikacji z LLM.',

    // Security
    'security.title': 'Architektura z bezpieczeÅ„stwem na pierwszym miejscu',
    'security.description': 'LLM Router zostaÅ‚ zbudowany z ochronÄ… danych w centrum, odpowiedni dla organizacji dowolnej wielkoÅ›ci, gdzie bezpieczeÅ„stwo danych ma znaczenie. KaÅ¼de Å¼Ä…danie moÅ¼e byÄ‡ automatycznie sprawdzane i anonimizowane przed transmisjÄ…â€”czy to do lokalnych modeli (vLLM, Ollama, LM Studio), czy dostawcÃ³w chmurowych. Zachowaj wraÅ¼liwe dane bezpiecznie w swojej infrastrukturze, opcjonalnie korzystajÄ…c z usÅ‚ug zewnÄ™trznych z wbudowanÄ… anonimizacjÄ…, zapewniajÄ…c zgodnoÅ›Ä‡ z RODO, HIPAA, SOC2 i innymi ramami regulacyjnymi.',
    'security.feature1': 'Automatyczne wykrywanie i maskowanie danych osobowych (zgodnoÅ›Ä‡ z RODO/CCPA/HIPAA)',
    'security.feature2': 'Wsparcie dla miÄ™dzynarodowych identyfikatorÃ³w: SSN, numery podatkowe, numery ID, numery rejestracyjne firm',
    'security.feature3': 'Maskowanie danych finansowych (numery kont, karty kredytowe, kwoty transakcji)',
    'security.feature4': 'Wykrywanie i usuwanie prompt injection z filtrowaniem warstwy bezpieczeÅ„stwa',
    'security.feature5': 'Walidacja sum kontrolnych wykrytych identyfikatorÃ³w zapewniajÄ…ca dokÅ‚adnoÅ›Ä‡',
    'security.feature6': 'Rozszerzalny silnik maskowania z obsÅ‚ugÄ… reguÅ‚ niestandardowych dla wymagaÅ„ branÅ¼owych',
    'security.feature7': 'Wymuszona anonimizacja z konfigurowalnymi strategiami dla caÅ‚ego payloadu',
    'security.feature8': 'Opcjonalna strategia anonimizacji lokalnego GenAI dla wdroÅ¼eÅ„ air-gapped',
    'security.code.comment1': '# =======================================',
    'security.code.comment2': '# PrzykÅ‚ad: Automatyczna anonimizacja',
    'security.code.comment3': '# Przed transmisjÄ… do LLM:',
    'security.code.comment4': '# Po anonimizacji:',

    // Performance
    'performance.title': 'Skalowalna optymalizacja zasobÃ³w',
    'performance.subtitle': 'Zaawansowane mechanizmy orkiestracji zapewniajÄ… maksymalnÄ… efektywnoÅ›Ä‡ i optymalne wykorzystanie zasobÃ³w, inteligentnie dystrybuujÄ…c obciÄ…Å¼enia miÄ™dzy dostawcÃ³w przy uÅ¼yciu konfigurowalnych strategii rÃ³wnowaÅ¼enia obciÄ…Å¼enia. Skaluje siÄ™ od wdroÅ¼eÅ„ na pojedynczym serwerze do rozproszonej infrastruktury produkcyjnej.',
    'performance.stat1.number': '4',
    'performance.stat1.label': 'Strategie rÃ³wnowaÅ¼enia obciÄ…Å¼enia',
    'performance.stat2.number': '3',
    'performance.stat2.label': 'Strategie anonimizacji',
    'performance.stat3.number': 'âˆ',
    'performance.stat3.label': 'ObsÅ‚ugiwanych dostawcÃ³w LLM',
    'performance.stat4.number': '15+',
    'performance.stat4.label': 'ReguÅ‚ maskowania danych osobowych',
    'performance.stat5.number': '100%',
    'performance.stat5.label': 'Open Source Apache 2.0',

    // Use Cases
    'usecases.title': 'Przypadki uÅ¼ycia',
    'usecases.subtitle': 'LLM Router dostarcza wartoÅ›Ä‡ w rÃ³Å¼norodnych scenariuszach dla zespoÅ‚Ã³w deweloperskich i operacyjnych. NiezaleÅ¼nie od tego, czy budujesz nowe aplikacje oparte na AI, modernizujesz istniejÄ…ce systemy czy eksperymentujesz z modelami, zapewnia elastycznÄ… infrastrukturÄ™ skalujÄ…cÄ… siÄ™ z Twoimi potrzebami.',
    'usecases.corporate.title': 'ğŸ¢ Scentralizowane zarzÄ…dzanie AI',
    'usecases.corporate.problem': '<strong>Wyzwanie:</strong> Rozproszony dostÄ™p do LLM w zespoÅ‚ach bez ujednoliconego zarzÄ…dzania, kontroli bezpieczeÅ„stwa czy widocznoÅ›ci kosztÃ³w.',
    'usecases.corporate.solution': '<strong>RozwiÄ…zanie:</strong> LLM Router centralizuje caÅ‚y ruch AI przez pojedynczÄ… bramÄ™, umoÅ¼liwiajÄ…c kompleksowe zarzÄ…dzanie danymi, automatycznÄ… zgodnoÅ›Ä‡ przez anonimizacjÄ™ danych osobowych oraz scentralizowanÄ… kontrolÄ™ dostÄ™pu zanim Å¼Ä…dania dotrÄ… do dostawcy.',
    'usecases.corporate.feature1': 'Scentralizowana kontrola dostÄ™pu i polityk',
    'usecases.corporate.feature2': 'PeÅ‚ny Å›lad audytu dla zgodnoÅ›ci',
    'usecases.corporate.feature3': 'Brak narzutu rate limitingu, zoptymalizowana przepustowoÅ›Ä‡',
    'usecases.highavailability.title': 'ğŸ“ˆ Systemy wysokiej dostÄ™pnoÅ›ci',
    'usecases.highavailability.problem': '<strong>Wyzwanie:</strong> Awarie dostawcÃ³w powodujÄ… caÅ‚kowity przestÃ³j aplikacji, zakÅ‚Ã³cajÄ…c operacje.',
    'usecases.highavailability.solution': '<strong>RozwiÄ…zanie:</strong> Automatyczne przeÅ‚Ä…czanie awaryjne miÄ™dzy dostawcami z ciÄ…gÅ‚ym monitorowaniem stanu i circuit breakerami. OsiÄ…gnij wysokÄ… dostÄ™pnoÅ›Ä‡ przez inteligentne rÃ³wnowaÅ¼enie obciÄ…Å¼enia, redundancjÄ™ dostawcÃ³w i routing ruchu w czasie rzeczywistym z opcjonalnÄ… anonimizacjÄ… w locie.',
    'usecases.highavailability.feature1': 'Dystrybucja obciÄ…Å¼enia miÄ™dzy wieloma dostawcami',
    'usecases.highavailability.feature2': 'Health checks w czasie rzeczywistym na dostawcÄ™',
    'usecases.highavailability.feature3': 'Automatyczne przeÅ‚Ä…czanie awaryjne i circuit breaking',
    'usecases.healthcare.title': 'ğŸ¥ Ochrona danych i zgodnoÅ›Ä‡',
    'usecases.healthcare.problem': '<strong>Wyzwanie:</strong> Surowe wymagania regulacyjne dotyczÄ…ce ochrony danych (RODO, HIPAA) z karami za naruszenia.',
    'usecases.healthcare.solution': '<strong>RozwiÄ…zanie:</strong> Przetwarzaj wraÅ¼liwe dokumenty z wbudowanÄ… ochronÄ… danych. Automatyczne maskowanie PHI, danych osobowych, numerÃ³w kont i wraÅ¼liwych identyfikatorÃ³w. Wymuszona anonimizacja niezaleÅ¼na od implementacji aplikacji zapewniajÄ…ca zgodnoÅ›Ä‡ na warstwie infrastruktury.',
    'usecases.healthcare.feature1': '15+ typÃ³w identyfikatorÃ³w z walidacjÄ…',
    'usecases.healthcare.feature2': 'Walidacja sum kontrolnych dla dokÅ‚adnoÅ›ci',
    'usecases.healthcare.feature3': 'Tryb wymuszonej anonimizacji',
    'usecases.local.title': 'ğŸ–¥ï¸ WÅ‚asne lokalne modele',
    'usecases.local.problem': '<strong>Wyzwanie:</strong> Uruchamianie modeli na lokalnej infrastrukturze (vLLM, Ollama, LM Studio) wymaga rÄ™cznego zarzÄ…dzania wieloma endpointami i protokoÅ‚ami.',
    'usecases.local.solution': '<strong>RozwiÄ…zanie:</strong> LLM Router zapewnia zunifikowane zarzÄ…dzanie wszystkimi lokalnymi wdroÅ¼eniami modeli. Uruchamiaj modele na wÅ‚asnym sprzÄ™cie z peÅ‚nÄ… kontrolÄ…, dystrybuuj obciÄ…Å¼enie miÄ™dzy wiele lokalnych instancji i opcjonalnie dodaj dostawcÃ³w chmurowych jako backup. Zachowaj dane i przetwarzanie caÅ‚kowicie w swojej infrastrukturze.',
    'usecases.local.feature1': 'PeÅ‚na suwerennoÅ›Ä‡ i kontrola nad danymi',
    'usecases.local.feature2': 'RÃ³wnowaÅ¼enie obciÄ…Å¼enia miÄ™dzy lokalnymi instancjami',
    'usecases.local.feature3': 'Opcjonalny fallback do chmury przy szczytowym obciÄ…Å¼eniu',
    'usecases.research.title': 'ğŸ”¬ Eksperymentowanie i testy A/B',
    'usecases.research.problem': '<strong>Wyzwanie:</strong> Testowanie rÃ³Å¼nych modeli i dostawcÃ³w wymaga zmian kodu i skomplikowanej konfiguracji infrastruktury.',
    'usecases.research.solution': '<strong>RozwiÄ…zanie:</strong> Eksperymentuj z lokalnymi modelami (vLLM, Ollama, LM Studio) i dostawcami chmurowymi bez Å¼adnych zmian w kodzie aplikacji. Routing sterowany konfiguracjÄ… umoÅ¼liwia pÅ‚ynne przeÅ‚Ä…czanie, testy A/B miÄ™dzy rÃ³Å¼nymi modelami i strategie zoptymalizowane pod kÄ…tem kosztÃ³w priorytetyzujÄ…ce lokalne wdroÅ¼enia.',
    'usecases.research.feature1': 'PorÃ³wnywanie wydajnoÅ›ci modeli lokalnych vs. chmurowych',
    'usecases.research.feature2': 'Testy A/B dowolnej kombinacji modeli',
    'usecases.research.feature3': 'Optymalizacja kosztÃ³w z routingiem lokalnym-najpierw',
    'usecases.realtime.title': 'ğŸš€ Przetwarzanie w czasie rzeczywistym z niskim opÃ³Åºnieniem',
    'usecases.realtime.problem': '<strong>Wyzwanie:</strong> OpÃ³Åºnienia przetwarzania i brak obsÅ‚ugi strumieniowania wpÅ‚ywajÄ…ce na doÅ›wiadczenie uÅ¼ytkownika w aplikacjach czasu rzeczywistego.',
    'usecases.realtime.solution': '<strong>RozwiÄ…zanie:</strong> LLM Router obsÅ‚uguje Server-Sent Events (SSE) i strumieniowanie odpowiedzi z automatycznÄ… konwersjÄ… protokoÅ‚Ã³w. Zoptymalizowany pod kÄ…tem minimalnego opÃ³Åºnienia z poolingiem poÅ‚Ä…czeÅ„, centralizacjÄ… Redis dla systemÃ³w rozproszonych i nieblokujÄ…cÄ… obsÅ‚ugÄ… Å¼Ä…daÅ„.',
    'usecases.realtime.feature1': 'Strumieniowanie SSE <span class="arrow-icon">&#8596;</span> konwersja Ollama',
    'usecases.realtime.feature2': 'Pooling poÅ‚Ä…czeÅ„ i pipelining',
    'usecases.realtime.feature3': 'Rozproszona koordynacja Redis',
    'usecases.legacy.title': 'âš¡ Modernizacja systemÃ³w legacy',
    'usecases.legacy.problem': '<strong>Wyzwanie:</strong> Aplikacje legacy nie majÄ… nowoczesnych interfejsÃ³w do integracji LLM, wymagajÄ…c obszernego refaktoringu.',
    'usecases.legacy.solution': '<strong>RozwiÄ…zanie:</strong> WdrÃ³Å¼ LLM Router jako ujednoliconÄ… warstwÄ™ proxy zapewniajÄ…cÄ… spÃ³jny dostÄ™p REST API z dowolnej aplikacjiâ€”niezaleÅ¼nie od wersji, architektury czy jÄ™zyka programowania. Modernizuj moÅ¼liwoÅ›ci AI bez refaktoringu istniejÄ…cych baz kodu.',
    'usecases.legacy.feature1': 'Ujednolicona brama REST API',
    'usecases.legacy.feature2': 'Uniwersalna kompatybilnoÅ›Ä‡ z dostawcami',
    'usecases.legacy.feature3': 'Integracja legacy bez zmian',

    // Open Source
    'opensource.title': 'Open Source i rozwÃ³j wspierany przez spoÅ‚ecznoÅ›Ä‡',
    'opensource.subtitle': 'Transparentny, rozszerzalny, gotowy do produkcji',
    'opensource.license': 'Licencja:',
    'opensource.description': 'LLM Router jest <strong>w peÅ‚ni open source</strong> na permisywnej licencji <strong>Apache 2.0</strong>, zapewniajÄ…c peÅ‚nÄ… swobodÄ™ <strong>uÅ¼ytku komercyjnego</strong>, <strong>modyfikacji</strong> i <strong>dystrybucji</strong>. Zbudowany na wspÃ³Å‚pracy spoÅ‚ecznoÅ›ci z transparentnÄ… architekturÄ… i audytowalnym kodem, moÅ¼esz go dostosowaÄ‡ do swoich konkretnych potrzeb, wnieÅ›Ä‡ ulepszenia i korzystaÄ‡ z ciÄ…gÅ‚ych ulepszeÅ„ spoÅ‚ecznoÅ›ciâ€”wszystko bez vendor lock-in czy ograniczeÅ„ licencyjnych.',
    'opensource.cta.star': 'â­ Gwiazdka na GitHub',
    'opensource.cta.issue': 'ğŸ’¡ ZgÅ‚oÅ› problem',
    'opensource.cta.contribute': 'ğŸ”§ WspÃ³Å‚twÃ³rz',

    // Contact
    'contact.title': 'Kontakt',
    'contact.subtitle': 'Masz pytania? Napisz do nas, a my odpowiemy bÅ‚yskawicznie!',

    // Footer
    'footer.project': 'Projekt',
    'footer.project.repo': 'Repozytorium GitHub',
    'footer.project.docs': 'Dokumentacja',
    'footer.project.changelog': 'Changelog',
    'footer.project.license': 'Licencja',
    'footer.components': 'Komponenty',
    'footer.community': 'SpoÅ‚ecznoÅ›Ä‡',
    'footer.community.issues': 'Issue Tracker',
    'footer.community.pulls': 'Pull Requests',
    'footer.community.discussions': 'Dyskusje',
    'footer.community.radlab': 'RadLab Dev Group',
    'footer.resources': 'Zasoby',
    'footer.resources.quickstart': 'Szybki start',
    'footer.resources.install': 'Instalacja',
    'footer.resources.docker': 'Obrazy Docker',
    'footer.resources.mlutils': 'ML Utils (zaleÅ¼noÅ›Ä‡)',
    'footer.copyright': 'Â© 2025 LLM-Router | Projekt Open Source | Licencja Apache 2.0',

    // Back to top
    'backToTop.aria': 'PowrÃ³t na gÃ³rÄ™',
  },

  en: {
    // Header
    'header.menu.aria': 'Open menu',
    'header.nav.description': 'Features',
    'header.nav.security': 'Security',
    'header.nav.performance': 'Performance',
    'header.nav.useCases': 'Use Cases',
    'header.nav.contact': 'Contact',
    'header.github.router.tooltip': 'main llm-router.cloud GitHub repository',
    'header.github.page.tooltip': 'llmrouter website on GitHub',

    // Hero
    'hero.title': 'Open-Source AI Gateway for Local and Cloud LLM Infrastructure',
    'hero.subtitle.reliable': 'Reliable',
    'hero.subtitle.text': 'routing for large language models with built-in',
    'hero.subtitle.security': 'data protection',
    'hero.description': 'LLM Router is a flexible, open-source gateway for managing both local LLM deployments (vLLM, Ollama, LM Studio) and cloud providers. It provides an intelligent layer between your applications and models, delivering real-time traffic management, intelligent load balancing across local and cloud providers, and comprehensive security controls including PII masking, data anonymization, and content filtering. Built with <strong>Apache 2.0</strong> license, it\'s designed for teams who want to run AI infrastructure locally with optional cloud provider supportâ€”giving you full control and flexibility.',
    'hero.cta.github': 'View on GitHub',
    'hero.cta.docs': 'Documentation',

    // Features
    'features.title': 'Comprehensive LLM Infrastructure Management',
    'features.subtitle': '<strong>Complete</strong> platform for managing <strong>local LLM deployments (vLLM, Ollama, LM Studio) and optionally cloud providers</strong> at any scale. Unified management with production-grade security and observability. Open-source architecture enables customization and community-driven enhancements. <strong>Run your models locally</strong> with full control over your infrastructure.',
    'features.anonymization.title': 'Built-in PII Anonymization',
    'features.anonymization.desc': 'High-performance <code>fast_masker</code> plugin automatically detects and masks sensitive data including national IDs, tax numbers, emails, account numbers, IP addresses, and more before transmission to LLM providers. GDPR and SOC2 compliant by design.',
    'features.loadbalancing.title': 'Flexible Load Balancing',
    'features.loadbalancing.desc': 'Four configurable load balancing strategies: <code>balanced</code>, <code>weighted</code>, <code>first_available</code>, <code>first_available_optim</code>. Optimize resource utilization and ensure high availability for any deployment size.',
    'features.routing.title': 'Unified Local & Cloud Routing',
    'features.routing.desc': 'Single REST API supporting local providers (Ollama, vLLM, LM Studio) and cloud services (OpenAI, Anthropic, etc.). Automatic protocol conversion, seamless switching between local and cloud providers, and intelligent load distribution across all endpoints.',
    'features.monitoring.title': 'Full Observability',
    'features.monitoring.desc': 'Native Prometheus integration delivering real-time metrics: request rates, latency percentiles, error rates per provider, and health checks. Complete visibility through Grafana dashboards with automatic service discovery and alerting.',
    'features.performance.title': 'High Performance',
    'features.performance.desc': 'Streaming responses, connection pooling, Redis broker for distributed deployments. Optimized for minimal latency and maximum throughput across various deployment scenarios.',
    'features.config.title': 'Easy Deployment',
    'features.config.desc': 'Infrastructure-as-code configuration via JSON and environment variables. Docker and Kubernetes ready with official images. Deploy in minutes with flexible configuration options for any environment.',
    'features.endpoints.title': 'Extensible Endpoints',
    'features.endpoints.desc': 'Ready-to-use endpoints for RAG pipelines, question generation, translation, and other common AI workflows. Easily extensible for custom use cases.',
    'features.web.title': 'Management Interfaces',
    'features.web.desc': 'Configuration Manager for centralized infrastructure control and Anonymizer interface for secure, compliant LLM communication.',

    // Security
    'security.title': 'Security-First Architecture',
    'security.description': 'LLM Router is built with data protection at its core, suitable for organizations of any size where data security matters. Every request can be automatically inspected and anonymized before transmissionâ€”whether to your local models (vLLM, Ollama, LM Studio) or cloud providers. Keep sensitive data secure within your infrastructure while optionally using external services with built-in anonymization, ensuring compliance with GDPR, HIPAA, SOC2, and other regulatory frameworks.',
    'security.feature1': 'Automatic PII detection and masking (GDPR/CCPA/HIPAA compliant)',
    'security.feature2': 'Support for international identifiers: SSN, tax IDs, national IDs, business registration numbers',
    'security.feature3': 'Financial data masking (account numbers, credit cards, transaction amounts)',
    'security.feature4': 'Prompt injection detection and removal with security layer filtering',
    'security.feature5': 'Checksum validation for detected identifiers ensuring accuracy',
    'security.feature6': 'Extensible masking engine with custom rule support for industry-specific requirements',
    'security.feature7': 'Enforced anonymization with configurable strategies across entire payload',
    'security.feature8': 'Optional local GenAI anonymization strategy for air-gapped deployments',
    'security.code.comment1': '# =======================================',
    'security.code.comment2': '# Example: Automatic Anonymization',
    'security.code.comment3': '# Before transmission to LLM:',
    'security.code.comment4': '# After anonymization:',

    // Performance
    'performance.title': 'Scalable Resource Optimization',
    'performance.subtitle': 'Advanced orchestration mechanisms deliver maximum efficiency and optimal resource utilization, intelligently distributing workloads across providers using configurable load balancing strategies. Scales from single-server deployments to distributed production infrastructure.',
    'performance.stat1.number': '4',
    'performance.stat1.label': 'Load Balancing Strategies',
    'performance.stat2.number': '3',
    'performance.stat2.label': 'Anonymization Strategies',
    'performance.stat3.number': 'âˆ',
    'performance.stat3.label': 'LLM Providers Supported',
    'performance.stat4.number': '15+',
    'performance.stat4.label': 'PII Masking Rules',
    'performance.stat5.number': '100%',
    'performance.stat5.label': 'Open Source Apache 2.0',

    // Use Cases
    'usecases.title': 'Use Cases',
    'usecases.subtitle': 'LLM Router delivers value across diverse scenarios for development and operations teams. Whether building new AI-powered applications, modernizing existing systems, or experimenting with models, it provides flexible infrastructure that scales with your needs.',
    'usecases.corporate.title': 'ğŸ¢ Centralized AI Management',
    'usecases.corporate.problem': '<strong>Challenge:</strong> Scattered LLM access across teams without unified governance, security controls, or cost visibility.',
    'usecases.corporate.solution': '<strong>Solution:</strong> LLM Router centralizes all AI traffic through a single gateway, enabling comprehensive data governance, automatic compliance through PII anonymization, and centralized access control before requests reach any provider.',
    'usecases.corporate.feature1': 'Centralized access and policy control',
    'usecases.corporate.feature2': 'Complete audit trail for compliance',
    'usecases.corporate.feature3': 'No rate limiting overhead, optimized throughput',
    'usecases.highavailability.title': 'ğŸ“ˆ High Availability Systems',
    'usecases.highavailability.problem': '<strong>Challenge:</strong> Provider outages cause complete application downtime, disrupting operations.',
    'usecases.highavailability.solution': '<strong>Solution:</strong> Automatic failover between providers with continuous health monitoring and circuit breakers. Achieve high uptime through intelligent load balancing, provider redundancy, and real-time traffic routing with optional in-flight anonymization.',
    'usecases.highavailability.feature1': 'Multi-provider load distribution',
    'usecases.highavailability.feature2': 'Real-time health checks per provider',
    'usecases.highavailability.feature3': 'Automatic failover and circuit breaking',
    'usecases.healthcare.title': 'ğŸ¥ Data Protection & Compliance',
    'usecases.healthcare.problem': '<strong>Challenge:</strong> Strict regulatory requirements for data protection (GDPR, HIPAA) with penalties for breaches.',
    'usecases.healthcare.solution': '<strong>Solution:</strong> Process sensitive documents with built-in data protection. Automatic masking of PHI, PII, account numbers, and sensitive identifiers. Enforced anonymization independent of application implementation ensuring compliance at the infrastructure layer.',
    'usecases.healthcare.feature1': '15+ identifier types with validation',
    'usecases.healthcare.feature2': 'Checksum validation for accuracy',
    'usecases.healthcare.feature3': 'Enforced anonymization mode',
    'usecases.local.title': 'ğŸ–¥ï¸ Self-Hosted Local Models',
    'usecases.local.problem': '<strong>Challenge:</strong> Running models on local infrastructure (vLLM, Ollama, LM Studio) requires managing multiple endpoints and protocols manually.',
    'usecases.local.solution': '<strong>Solution:</strong> LLM Router provides unified management for all your local model deployments. Run models on your own hardware with full control, distribute load across multiple local instances, and optionally add cloud providers as backup. Keep data and processing entirely within your infrastructure.',
    'usecases.local.feature1': 'Full data sovereignty and control',
    'usecases.local.feature2': 'Load balancing across local model instances',
    'usecases.local.feature3': 'Optional cloud fallback for peak loads',
    'usecases.research.title': 'ğŸ”¬ Model Experimentation & A/B Testing',
    'usecases.research.problem': '<strong>Challenge:</strong> Testing different models and providers requires code changes and complex infrastructure setup.',
    'usecases.research.solution': '<strong>Solution:</strong> Experiment with local models (vLLM, Ollama, LM Studio) and cloud providers without any application code changes. Configuration-driven routing enables seamless switching, A/B testing between different models, and cost-optimized strategies that prioritize local deployments.',
    'usecases.research.feature1': 'Compare local vs. cloud model performance',
    'usecases.research.feature2': 'A/B testing any model combination',
    'usecases.research.feature3': 'Cost optimization with local-first routing',
    'usecases.realtime.title': 'ğŸš€ Low-Latency Real-Time Processing',
    'usecases.realtime.problem': '<strong>Challenge:</strong> Processing delays and lack of streaming support impacting user experience in real-time applications.',
    'usecases.realtime.solution': '<strong>Solution:</strong> LLM Router supports Server-Sent Events (SSE) and response streaming with automatic protocol conversion. Optimized for minimal latency with connection pooling, Redis centralization for distributed systems, and non-blocking request handling.',
    'usecases.realtime.feature1': 'SSE streaming <span class="arrow-icon">&#8596;</span> Ollama conversion',
    'usecases.realtime.feature2': 'Connection pooling and pipelining',
    'usecases.realtime.feature3': 'Distributed Redis coordination',
    'usecases.legacy.title': 'âš¡ Legacy System Modernization',
    'usecases.legacy.problem': '<strong>Challenge:</strong> Legacy applications lack modern interfaces for LLM integration, requiring extensive refactoring.',
    'usecases.legacy.solution': '<strong>Solution:</strong> Deploy LLM Router as a unified proxy layer providing consistent REST API access from any applicationâ€”regardless of version, architecture, or programming language. Modernize AI capabilities without refactoring existing codebases.',
    'usecases.legacy.feature1': 'Unified REST API gateway',
    'usecases.legacy.feature2': 'Universal provider compatibility',
    'usecases.legacy.feature3': 'Zero-touch legacy integration',

    // Open Source
    'opensource.title': 'Open Source & Community-Driven',
    'opensource.subtitle': 'Transparent, extensible, production-ready',
    'opensource.license': 'License:',
    'opensource.description': 'LLM Router is <strong>fully open source</strong> under the permissive <strong>Apache 2.0</strong> license, providing complete freedom for <strong>commercial use</strong>, <strong>modification</strong>, and <strong>distribution</strong>. Built on community collaboration with transparent architecture and auditable code, you can customize it for your specific needs, contribute improvements, and benefit from ongoing community enhancementsâ€”all without vendor lock-in or licensing constraints.',
    'opensource.cta.star': 'â­ Star on GitHub',
    'opensource.cta.issue': 'ğŸ’¡ Report Issue',
    'opensource.cta.contribute': 'ğŸ”§ Contribute',

    // Contact
    'contact.title': 'Contact',
    'contact.subtitle': 'Have questions? Write to us, and we\'ll respond in a flash!',

    // Footer
    'footer.project': 'Project',
    'footer.project.repo': 'GitHub Repository',
    'footer.project.docs': 'Documentation',
    'footer.project.changelog': 'Changelog',
    'footer.project.license': 'License',
    'footer.components': 'Components',
    'footer.community': 'Community',
    'footer.community.issues': 'Issue Tracker',
    'footer.community.pulls': 'Pull Requests',
    'footer.community.discussions': 'Discussions',
    'footer.community.radlab': 'RadLab Dev Group',
    'footer.resources': 'Resources',
    'footer.resources.quickstart': 'Quick Start',
    'footer.resources.install': 'Installation',
    'footer.resources.docker': 'Docker Images',
    'footer.resources.mlutils': 'ML Utils (dependency)',
    'footer.copyright': 'Â© 2025 LLM-Router | Open Source Project | Licensed under Apache 2.0',

    // Back to top
    'backToTop.aria': 'Back to top',
  }
};
