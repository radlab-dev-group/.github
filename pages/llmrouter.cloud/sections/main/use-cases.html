<section id="use-cases" class="use-cases">
    <div class="container">
        <h2 class="section-title" data-i18n="usecases.title">Use Cases</h2>
        <p class="section-subtitle" data-i18n="usecases.subtitle">
            LLM Router delivers value across diverse scenarios for development and operations teams.
            Whether building new AI-powered applications, modernizing existing systems, or experimenting with models,
            it provides flexible infrastructure that scales with your needs.
        </p>
        <div class="use-case-list">

            <div class="use-case">
                <h3 data-i18n="usecases.corporate.title">üè¢ Centralized AI Management</h3>
                <p data-i18n="usecases.corporate.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Scattered LLM access across teams without unified governance, security controls, or cost visibility.
                </p>
                <p data-i18n="usecases.corporate.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    LLM Router centralizes all AI traffic through a single gateway,
                    enabling comprehensive data governance, automatic compliance through PII anonymization,
                    and centralized access control before requests reach any provider.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.corporate.feature1">Centralized access and policy control</li>
                    <li data-i18n="usecases.corporate.feature2">Complete audit trail for compliance</li>
                    <li data-i18n="usecases.corporate.feature3">No rate limiting overhead, optimized throughput</li>
                </ul>
            </div>

            <div class="use-case">
                <h3 data-i18n="usecases.highavailability.title">üìà High Availability Systems</h3>
                <p data-i18n="usecases.highavailability.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Provider outages cause complete application downtime, disrupting operations.
                </p>
                <p data-i18n="usecases.highavailability.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    Automatic failover between providers with continuous health monitoring and circuit breakers.
                    Achieve high uptime through intelligent load balancing, provider redundancy, and real-time traffic routing with optional in-flight anonymization.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.highavailability.feature1">Multi-provider load distribution</li>
                    <li data-i18n="usecases.highavailability.feature2">Real-time health checks per provider</li>
                    <li data-i18n="usecases.highavailability.feature3">Automatic failover and circuit breaking</li>
                </ul>
            </div>

            <div class="use-case">
                <h3 data-i18n="usecases.healthcare.title">üè• Data Protection & Compliance</h3>
                <p data-i18n="usecases.healthcare.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Strict regulatory requirements for data protection (GDPR, HIPAA) with penalties for breaches.
                </p>
                <p data-i18n="usecases.healthcare.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    Process sensitive documents with built-in data protection.
                    Automatic masking of PHI, PII, account numbers, and sensitive identifiers. Enforced anonymization independent of application implementation ensuring compliance at the infrastructure layer.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.healthcare.feature1">15+ identifier types with validation</li>
                    <li data-i18n="usecases.healthcare.feature2">Checksum validation for accuracy</li>
                    <li data-i18n="usecases.healthcare.feature3">Enforced anonymization mode</li>
                </ul>
            </div>

            <div class="use-case">
                <h3 data-i18n="usecases.local.title">üñ•Ô∏è Self-Hosted Local Models</h3>
                <p data-i18n="usecases.local.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Running models on local infrastructure (vLLM, Ollama, LM Studio) requires managing multiple endpoints and protocols manually.
                </p>
                <p data-i18n="usecases.local.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    LLM Router provides unified management for all your local model deployments. Run models on your own hardware with full control, distribute load across multiple local instances, and optionally add cloud providers as backup. Keep data and processing entirely within your infrastructure.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.local.feature1">Full data sovereignty and control</li>
                    <li data-i18n="usecases.local.feature2">Load balancing across local model instances</li>
                    <li data-i18n="usecases.local.feature3">Optional cloud fallback for peak loads</li>
                </ul>
            </div>

            <div class="use-case">
                <h3 data-i18n="usecases.research.title">üî¨ Model Experimentation & A/B Testing</h3>
                <p data-i18n="usecases.research.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Testing different models and providers requires code changes and complex infrastructure setup.
                </p>
                <p data-i18n="usecases.research.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    Experiment with local models (vLLM, Ollama, LM Studio) and cloud providers without any application code changes.
                    Configuration-driven routing enables seamless switching, A/B testing between different models, and cost-optimized strategies that prioritize local deployments.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.research.feature1">Compare local vs. cloud model performance</li>
                    <li data-i18n="usecases.research.feature2">A/B testing any model combination</li>
                    <li data-i18n="usecases.research.feature3">Cost optimization with local-first routing</li>
                </ul>
            </div>


            <div class="use-case">
                <h3 data-i18n="usecases.realtime.title">üöÄ Low-Latency Real-Time Processing</h3>
                <p data-i18n="usecases.realtime.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Processing delays and lack of streaming support impacting user experience in real-time applications.
                </p>
                <p data-i18n="usecases.realtime.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    LLM Router supports Server-Sent Events (SSE) and response streaming with automatic protocol conversion.
                    Optimized for minimal latency with connection pooling, Redis centralization for distributed systems, and non-blocking request handling.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.realtime.feature1" data-i18n-html="true">SSE streaming <span class="arrow-icon">&#8596;</span> Ollama conversion</li>
                    <li data-i18n="usecases.realtime.feature2">Connection pooling and pipelining</li>
                    <li data-i18n="usecases.realtime.feature3">Distributed Redis coordination</li>
                </ul>
            </div>

            <div class="use-case">
                <h3 data-i18n="usecases.legacy.title">‚ö° Legacy System Modernization</h3>
                <p data-i18n="usecases.legacy.problem" data-i18n-html="true">
                    <strong>Challenge:</strong>
                    Legacy applications lack modern interfaces for LLM integration, requiring extensive refactoring.
                </p>
                <p data-i18n="usecases.legacy.solution" data-i18n-html="true">
                    <strong>Solution:</strong>
                    Deploy LLM Router as a unified proxy layer providing consistent REST API access from any application‚Äîregardless of version, architecture, or programming language. Modernize AI capabilities without refactoring existing codebases.
                </p>
                <ul class="use-case-features">
                    <li data-i18n="usecases.legacy.feature1">Unified REST API gateway</li>
                    <li data-i18n="usecases.legacy.feature2">Universal provider compatibility</li>
                    <li data-i18n="usecases.legacy.feature3">Zero-touch legacy integration</li>
                </ul>
            </div>
        </div>

    </div>
</section>
