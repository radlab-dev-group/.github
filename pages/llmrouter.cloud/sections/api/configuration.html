<section id="configuration" class="tech-section"
         style="background: radial-gradient(circle at 50% 0%, rgba(15, 23, 42, 0.95), rgba(2, 6, 23, 1)); padding: 3rem 0;">
    <div class="container">
        <h2 class="section-title">Configuration</h2>
        <p class="section-subtitle">Environment variables and model configuration</p>

        <h3 style="color: var(--fg); margin-top: 2rem;">Key Environment Variables</h3>
        <table class="env-var-table">
            <thead>
            <tr>
                <th>Variable</th>
                <th>Description</th>
                <th>Default</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td>LLM_ROUTER_PROMPTS_DIR</td>
                <td>Directory containing system prompt files.</td>
                <td>resources/prompts</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_MODELS_CONFIG</td>
                <td>Path to the JSON file defining models and providers.</td>
                <td>resources/configs/models-config.json</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_EXTERNAL_TIMEOUT</td>
                <td>HTTP timeout (seconds) for outbound LLM calls.</td>
                <td>300</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_TIMEOUT</td>
                <td>Timeout for the proxy server itself.</td>
                <td>0 (no timeout)</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_LOG_FILENAME</td>
                <td>Log file name for the router.</td>
                <td>llm-router.log</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_LOG_LEVEL</td>
                <td>Logging level (DEBUG, INFO, …).</td>
                <td>INFO</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_EP_PREFIX</td>
                <td>Global URL prefix (e.g., /api).</td>
                <td>/api</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_MINIMUM</td>
                <td>Must be set to enable proxy mode (1/true).</td>
                <td><em>required</em></td>
            </tr>
            <tr>
                <td>LLM_ROUTER_BALANCE_STRATEGY</td>
                <td>Load‑balancing strategy (balanced, weighted, first_available, first_available_optim).</td>
                <td>balanced</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_REDIS_HOST</td>
                <td>Redis connection host for provider locking/monitoring.</td>
                <td>-</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_REDIS_PORT</td>
                <td>Redis connection port for provider locking/monitoring.</td>
                <td>6379</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_REDIS_PASSWORD</td>
                <td>Password for Redis connection.</td>
                <td>None</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_REDIS_DB</td>
                <td>Redis database number.</td>
                <td>0</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_USE_PROMETHEUS</td>
                <td>Enable Prometheus metrics (1/true).</td>
                <td>False</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_TYPE</td>
                <td>Server backend (flask, gunicorn, waitress).</td>
                <td>flask</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_PORT</td>
                <td>Port the server listens on.</td>
                <td>8080</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_HOST</td>
                <td>Host/interface to bind.</td>
                <td>0.0.0.0</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_WORKERS_COUNT</td>
                <td>Number of workers (Gunicorn/Waitress).</td>
                <td>2</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_THREADS_COUNT</td>
                <td>Number of threads per worker.</td>
                <td>8</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVER_WORKER_CLASS</td>
                <td>Gunicorn worker class (e.g., gevent).</td>
                <td></td>
            </tr>
            <tr>
                <td>LLM_ROUTER_FORCE_GUARDRAIL_REQUEST</td>
                <td>Force guardrail evaluation on every request.</td>
                <td>False</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_GUARDRAIL_WITH_AUDIT_REQUEST</td>
                <td>Audits all guardrail decisions (request).</td>
                <td>False</td>
            </tr>
            <tr>
                <td>GUARDRAIL_STRATEGY_PIPELINE_REQUEST</td>
                <td>Ordered list of guardrail strategies (request).</td>
                <td>-</td>
            </tr>
            <!--            <tr>-->
            <!--                <td>LLM_ROUTER_FORCE_GUARDRAIL_RESPONSE</td>-->
            <!--                <td>Force guardrail evaluation on every response before user receives the result.</td>-->
            <!--                <td>False</td>-->
            <!--            </tr>-->
            <!--            <tr>-->
            <!--                <td>LLM_ROUTER_GUARDRAIL_WITH_AUDIT_RESPONSE</td>-->
            <!--                <td>Audits all guardrail decisions (response).</td>-->
            <!--                <td>False</td>-->
            <!--            </tr>-->
            <!--            <tr>-->
            <!--                <td>GUARDRAIL_STRATEGY_PIPELINE_RESPONSE</td>-->
            <!--                <td>Ordered list of guardrail strategies (response).</td>-->
            <!--                <td>-</td>-->
            <!--            </tr>-->
            <tr>
                <td>LLM_ROUTER_FORCE_MASKING</td>
                <td>Each request payload will be fully masked.</td>
                <td>False</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_MASKING_WITH_AUDIT</td>
                <td>Each masking operation is recorded in an audit log.</td>
                <td>False</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_MASKING_STRATEGY_PIPELINE</td>
                <td>Defines the ordered list of masking strategies.</td>
                <td>['fast_masker']</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_GUARDRAIL_NASK_GUARD_HOST</td>
                <td>Host and port address with the <code>naskguard</code>
                    service running, <strong>NOTE!</strong> Read
                    the plugin license before using the proposed model!
                </td>
                <td>-</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_GUARDRAIL_SOJKA_GUARD_HOST</td>
                <td>Host and port address with the <code>sojkaguard</code>
                    service running.
                </td>
                <td>-</td>
            </tr>
            <tr>
                <td>LLM_ROUTER_SERVICES_MONITOR_INTERVAL_SECONDS</td>
                <td>Time interval to check services availability.
                    Values lower than <code>1</code> will be treated as
                    <strong>not-use monitor</strong> and monitor will not be started.
                </td>
                <td>-</td>
            </tr>
            </tbody>
        </table>

        <h3 style="color: var(--fg); margin-top: 2.5rem;">Model Configuration (JSON)</h3>
        <div class="code-block" data-lang="json">
<pre><code>{
  "active_models": {
    "openai_models": ["openai-gptoss120b-1", "openai-gptoss120b-2"],
  },
  "openai_models": {
    "gpt-oss:120b": {
      "providers": [
        {
          "id": "openai-gptoss120b-1",
          "api_host": "http://192.1.1.20:11434",
          "api_token": "<not used>",
          "api_type": "ollama",
          "input_size": 32000,
          "model_path": ""
        },
        {
          "id": "openai-gptoss120b-2",
          "api_host": "http://192.1.1.55:7000",
          "api_token": "<not used>",
          "api_type": "vllm",
          "input_size": 32000,
          "model_path": ""
        }
      ]
    }
  }
}</code></pre>
        </div>
    </div>
</section>